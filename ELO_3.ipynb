{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/celo.png\" style=\"width:1000px;height:150px;\">\n",
    "\n",
    "\n",
    "This was a Kaggle competition, which aimed to develop machine learning algorithms to identify and serve the most relevant opportunities for individuals, revealing a sign of customer loyalty. Improve customer’s experience by proposing strategies to help Elo reduce unwanted campaigns to groups of customers is also explored. (https://www.kaggle.com/c/elo-merchant-category-recommendation ). \n",
    "\n",
    "In this report/code a very detailed solution is presented. Tools used are presented and key strategic data analysis functions are explained. The solution has some functions/strategies also used by Chau Ngoc Huynh’s kernel. The intention is to make the explanation more accessible to people who are starting to study Data Science / Machine Learning. We believe that through this file some people can learn a bit how to manipulate data, start a contact with one Machine Learning model, and get used to search the libraries and the methods used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/elo/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(4590)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you are interested in knowing a bit more about each of the libraries and modules used, please check summary below:\n",
    "\n",
    "<img src=\"images/introduction.PNG\" style=\"width:1000px;height:650px;\">\n",
    "\n",
    "\n",
    "\n",
    "### Links/References available at :\n",
    "- [NumPy](https://docs.scipy.org/doc/numpy-1.12.0/reference/index.html)\n",
    "- [Pandas](pandas.pydata.org/pandas-docs/stable/) \n",
    "- [datetime](https://docs.python.org/3/library/datetime.html#module-datetime)\n",
    "- [gc](https://docs.python.org/2/library/gc.html)\n",
    "- [matplotlib.pyplot](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.html#module-matplotlib.pyplot)\n",
    "- [Seaborn](https://seaborn.pydata.org/) \n",
    "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/genindex.html)\n",
    "- [Scikit-learn](https://scikit-learn.org/stable/)\n",
    "- [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), \n",
    "- [Mean Squared Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting \"Comma Separated Values\" (CSV) file into a DataFrame:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_hist_trans = pd.read_csv('historical_transactions.csv')\n",
    "df_new_merchant_trans = pd.read_csv('new_merchant_transactions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying `df.head(n)`, which will return the first \"n\" rows. `IPython.display` is used in order to make possible to see all information in only one cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0            2017-06  C_ID_92a2005557          5          2          1   \n",
       "1            2017-01  C_ID_3d0044924f          4          1          0   \n",
       "\n",
       "     target  \n",
       "0 -0.820283  \n",
       "1  0.392913  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>card_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>category_2</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.703331</td>\n",
       "      <td>2017-06-25 15:33:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.733128</td>\n",
       "      <td>2017-07-15 12:10:45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  authorized_flag          card_id  city_id category_1  installments  \\\n",
       "0               Y  C_ID_4e6213e9bc       88          N             0   \n",
       "1               Y  C_ID_4e6213e9bc       88          N             0   \n",
       "\n",
       "  category_3  merchant_category_id      merchant_id  month_lag  \\\n",
       "0          A                    80  M_ID_e020e9b302         -8   \n",
       "1          A                   367  M_ID_86ec983688         -7   \n",
       "\n",
       "   purchase_amount        purchase_date  category_2  state_id  subsector_id  \n",
       "0        -0.703331  2017-06-25 15:33:07         1.0        16            37  \n",
       "1        -0.733128  2017-07-15 12:10:45         1.0        16            16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04</td>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3\n",
       "0            2017-04  C_ID_0ab67a22ab          3          3          1\n",
       "1            2017-01  C_ID_130fd0cbdd          2          3          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>card_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>category_2</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_415bb3a509</td>\n",
       "      <td>107</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>307</td>\n",
       "      <td>M_ID_b0c793002c</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.557574</td>\n",
       "      <td>2018-03-11 14:57:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_415bb3a509</td>\n",
       "      <td>140</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>307</td>\n",
       "      <td>M_ID_88920c89e8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.569580</td>\n",
       "      <td>2018-03-19 18:53:37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  authorized_flag          card_id  city_id category_1  installments  \\\n",
       "0               Y  C_ID_415bb3a509      107          N             1   \n",
       "1               Y  C_ID_415bb3a509      140          N             1   \n",
       "\n",
       "  category_3  merchant_category_id      merchant_id  month_lag  \\\n",
       "0          B                   307  M_ID_b0c793002c          1   \n",
       "1          B                   307  M_ID_88920c89e8          1   \n",
       "\n",
       "   purchase_amount        purchase_date  category_2  state_id  subsector_id  \n",
       "0        -0.557574  2018-03-11 14:57:36         1.0         9            19  \n",
       "1        -0.569580  2018-03-19 18:53:37         1.0         9            19  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head(2))\n",
    "display(df_hist_trans.head(2))\n",
    "display(df_test.head(2))\n",
    "display(df_new_merchant_trans.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The `df.info( )` method is useful to get a data description from a data frame, in particular, the total number of rows, each attribute’s type and number of non-null values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201917 entries, 0 to 201916\n",
      "Data columns (total 6 columns):\n",
      "first_active_month    201917 non-null object\n",
      "card_id               201917 non-null object\n",
      "feature_1             201917 non-null int64\n",
      "feature_2             201917 non-null int64\n",
      "feature_3             201917 non-null int64\n",
      "target                201917 non-null float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 9.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29112361 entries, 0 to 29112360\n",
      "Data columns (total 14 columns):\n",
      "authorized_flag         object\n",
      "card_id                 object\n",
      "city_id                 int64\n",
      "category_1              object\n",
      "installments            int64\n",
      "category_3              object\n",
      "merchant_category_id    int64\n",
      "merchant_id             object\n",
      "month_lag               int64\n",
      "purchase_amount         float64\n",
      "purchase_date           object\n",
      "category_2              float64\n",
      "state_id                int64\n",
      "subsector_id            int64\n",
      "dtypes: float64(2), int64(6), object(6)\n",
      "memory usage: 3.0+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123623 entries, 0 to 123622\n",
      "Data columns (total 5 columns):\n",
      "first_active_month    123622 non-null object\n",
      "card_id               123623 non-null object\n",
      "feature_1             123623 non-null int64\n",
      "feature_2             123623 non-null int64\n",
      "feature_3             123623 non-null int64\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 4.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1963031 entries, 0 to 1963030\n",
      "Data columns (total 14 columns):\n",
      "authorized_flag         object\n",
      "card_id                 object\n",
      "city_id                 int64\n",
      "category_1              object\n",
      "installments            int64\n",
      "category_3              object\n",
      "merchant_category_id    int64\n",
      "merchant_id             object\n",
      "month_lag               int64\n",
      "purchase_amount         float64\n",
      "purchase_date           object\n",
      "category_2              float64\n",
      "state_id                int64\n",
      "subsector_id            int64\n",
      "dtypes: float64(2), int64(6), object(6)\n",
      "memory usage: 209.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.info())\n",
    "display(df_hist_trans.info())\n",
    "display(df_test.info())\n",
    "display(df_new_merchant_trans.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this point, an analysis over missing values in each data frame is performed. An anonymous function, also known as $\\lambda $ *(lambda)* functions was elaborated to point it out the quantity of null values in each data set. The syntax of Lambda function in python is `lambda arguments: expression`. In our case, we applied:**\n",
    "\n",
    "```python\n",
    "df.apply(lambda x: sum(x.isnull()), axis=0)\n",
    "```\n",
    "\n",
    "**Ps. It is possible to use different methods to measure null values (missing values) in a data frame, which means that it is not necessary to create a *lambda* function for that. However, in our study we did elaborated that mainly because we are aiming to have a simple and understandable code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------df_train-------\n",
      "first_active_month    0\n",
      "card_id               0\n",
      "feature_1             0\n",
      "feature_2             0\n",
      "feature_3             0\n",
      "target                0\n",
      "dtype: int64\n",
      "-------df_test-------\n",
      "first_active_month    1\n",
      "card_id               0\n",
      "feature_1             0\n",
      "feature_2             0\n",
      "feature_3             0\n",
      "dtype: int64\n",
      "-------df_hist_trans-------\n",
      "authorized_flag               0\n",
      "card_id                       0\n",
      "city_id                       0\n",
      "category_1                    0\n",
      "installments                  0\n",
      "category_3               178159\n",
      "merchant_category_id          0\n",
      "merchant_id              138481\n",
      "month_lag                     0\n",
      "purchase_amount               0\n",
      "purchase_date                 0\n",
      "category_2              2652864\n",
      "state_id                      0\n",
      "subsector_id                  0\n",
      "dtype: int64\n",
      "-------df_new_merchant_trans-------\n",
      "authorized_flag              0\n",
      "card_id                      0\n",
      "city_id                      0\n",
      "category_1                   0\n",
      "installments                 0\n",
      "category_3               55922\n",
      "merchant_category_id         0\n",
      "merchant_id              26216\n",
      "month_lag                    0\n",
      "purchase_amount              0\n",
      "purchase_date                0\n",
      "category_2              111745\n",
      "state_id                     0\n",
      "subsector_id                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dic = {'df_train': df_train, 'df_test': df_test, 'df_hist_trans': df_hist_trans, 'df_new_merchant_trans': df_new_merchant_trans }\n",
    "for name, df in dic.items():\n",
    "    print(\"-------\" + name + \"-------\")\n",
    "    print(df.apply(lambda x: sum(x.isnull()), axis=0)) #axis=0 define que a função deve ser aplicada em cada coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the data frame `df_test`, only one value was lost, located in the \"first_active_month\" column. Approach followed in this case was remove the row that have this missing value. For more information regarding function used to do that, please see:** [pandas.DataFrame.dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the other data frames (that presented a significant amount of missing values per data set), replace the missing value followed a different approach. The mode (most frequent value in a range) of each collum took the place of the missing values. In order to do that, it is first necessary to know the most frequent value in each case, `df[columns].mode()` was used and results are presented below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value that appears most often in column category_2 of the df_hist_trans\n",
      "0    1.0\n",
      "dtype: float64\n",
      "The value that appears most often in column category_3 of the df_hist_trans\n",
      "0    A\n",
      "dtype: object\n",
      "The value that appears most often in column merchant_id of the df_hist_trans\n",
      "0    M_ID_00a6ca8a8a\n",
      "dtype: object\n",
      "The value that appears most often in column category_2 of the df_new_merchant_trans\n",
      "0    1.0\n",
      "dtype: float64\n",
      "The value that appears most often in column category_3 of the df_new_merchant_trans\n",
      "0    A\n",
      "dtype: object\n",
      "The value that appears most often in column merchant_id of the df_new_merchant_trans\n",
      "0    M_ID_00a6ca8a8a\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "dic = {'df_hist_trans': df_hist_trans, 'df_new_merchant_trans': df_new_merchant_trans}\n",
    "for name, df in dic.items():\n",
    "    for columns in ('category_2', 'category_3','merchant_id' ):\n",
    "        print('The value that appears most often in column ' + columns + ' of the ' + name)\n",
    "        print(df[columns].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, `fillna` method is applied to fill up the columns. In order to do that, the mode and data set have to be mention in the code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "    df['category_2'].fillna(1.0,inplace=True)\n",
    "    df['category_3'].fillna('A',inplace=True)\n",
    "    df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An analysis over the \"target\" column in the `df_train` dataframe is performed. The aim of this analysis is to verify the existence of outliers. A simple method to do that is plot its histogram, in order to do that we used `plot.hist`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['target'].plot.hist(grid=True, bins=20, rwidth=0.9, color='k')\n",
    "plt.title('Target Frequency')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was possible to see that the interval $[-30,-18]$ does not contain any value. On the other hand, it was observed values up to 18. Therefore, it is possible to justify that any other value less than -18 is an outlier and furthermore, a collum is created (outlier collum) and those values are set as 1.\n",
    "\n",
    "\n",
    "Analysis can be check using the piece of code below:\n",
    "\n",
    "```python\n",
    "\n",
    "In [] len([1 for i in df_train['target'] if i>-30 and i<-18])\n",
    "Out[] 0\n",
    "In []len([1 for i in df_train['target'] if i>18]) \n",
    "Out[] 0 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199710\n",
       "1      2207\n",
       "Name: outliers, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['outliers'] = 0\n",
    "df_train.loc[df_train['target'] < -18, 'outliers'] = 1\n",
    "df_train['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features 1, 2 and 3 are not well described in the data set provided by the company. We only know that they are categorical variables defined by integer numbers and they are respectively $[1,5]$, $[1,3]$ and $[0,1]$. Therefore, one interesting thing to do at this stage is to add these \"categorical\" information for a more relevante variable (or at least give them a weight). Therefore, the following pice of code does perform a group of those features (by its mean) and add each of the three collums at train and test data frame with this new value.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['feature_1','feature_2','feature_3']:\n",
    "    order_label = df_train.groupby([f])['target'].mean()\n",
    "    df_train[f+'_groupby_target'] = df_train[f].map(order_label)\n",
    "    df_test[f+'_groupby_target'] = df_test[f].map(order_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Eng. is now performed. First, data/time features are analyzed and created. In the `df_train` and `df_test`, the \"first active month\" feature is presented as month/year. Therefore, two new collums are added (month and year). On the other hand, for `df_hist_trans` and `df_new_merchant_trans` the \"purchase date\" feature is a full date/time cell and six new collums are created, information such as year, weekend and hour is now presented separately from others:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train,df_test]:\n",
    "    df['first_active_month'] =  pd.to_datetime(df['first_active_month'])\n",
    "    df['activation_month'] = df['first_active_month'].dt.month\n",
    "    df['activation_year'] = df['first_active_month'].dt.year\n",
    "    del df['first_active_month']\n",
    "    \n",
    "for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date']) \n",
    "    df['year_of_purchase'] = df['purchase_date'].dt.year\n",
    "    df['month_of_purchase'] = df['purchase_date'].dt.month\n",
    "    df['week_of_year_purchase'] = df['purchase_date'].dt.weekofyear\n",
    "    df['day_of_week_purchase'] = df['purchase_date'].dt.dayofweek\n",
    "    df['weekend_purchase'] = (df['purchase_date'].dt.weekday >=5).astype(int)\n",
    "    df['hour_of_purchase'] = df['purchase_date'].dt.hour\n",
    "    df['purchase_date'] = df['purchase_date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other categorical features, such as \"authorized flag\" and \"category 1\" that has a nominal observation as an informatios (\"yes\" and \"no\") are convert to numerical data (\"0\" and \"1\"), and feture \"cagegory 3\", which has nominal values (\"A\",\"B\" and \"C\") will be replaced respectively by values \"1, 2 and 3\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "    df['authorized_flag'] = df['authorized_flag'].map({'Y':1, 'N':0})\n",
    "    df['category_1'] = df['category_1'].map({'Y':1, 'N':0})\n",
    "    df['category_3'] = df['category_3'].map({'A':1, 'B':2, 'C':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The next two pieces of code intends to create more features through of some features that we have. The idea below was based on ideas presented on kaggle's kernel [My first kernel](https://www.kaggle.com/chauhuynh/my-first-kernel-3-699 ).**\n",
    "\n",
    "1. Step\n",
    "Create a function that the arggument is a dictionary to create feature names\n",
    "\n",
    "2. Step\n",
    "Define new features\n",
    "\n",
    "3. Step\n",
    "Create more features based on features that we just defined\n",
    "\n",
    "4. Step\n",
    "Merge all the dataframes (df_hist_trans,df_new_merchant_trans) into test and train (df_train and df_test)\n",
    "\n",
    "5. Step\n",
    "Delete the dataframes that will not be use (df_hist_trans,df_new_merchant_trans) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_columns(dic):\n",
    "    return [k + '_' + value for k in dic.keys() for value in dic[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "\n",
    "dic['purchase_amount'] = ['sum','max','min','mean','var']\n",
    "dic['installments'] = ['mean','var']\n",
    "dic['month_lag'] = ['max','min','mean','var']\n",
    "dic['card_id'] = ['size']\n",
    "\n",
    "new_columns = get_new_columns(dic)\n",
    "new_columns.insert(0, 'card_id')\n",
    "#     df_group = df\n",
    "#     df_group = df_hist_group.groupby('card_id').agg(dic)\n",
    "#     df_group.columns = new_columns\n",
    "\n",
    "#     df_group.reset_index(drop=False,inplace=True)   \n",
    "#     df = df.merge(df_group,on='card_id',how='left')\n",
    "#     del df['purchase_date']\n",
    "#     df_train = df_train.merge(df,on='card_id',how='left')\n",
    "#     df_test = df_test.merge(df,on='card_id',how='left')\n",
    "#     del df;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_hist_trans.groupby('card_id').agg(dic)\n",
    "df_temp.reset_index(level=0, inplace=True)\n",
    "df_temp.columns = new_columns\n",
    "df_temp = df_hist_trans.merge(df_temp,on='card_id',how='left')\n",
    "df_train = df_train.merge(df_temp,on='card_id',how='left')\n",
    "df_test = df_test.merge(df_temp,on='card_id',how='left')\n",
    "del df_temp ;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_new_merchant_trans.groupby('card_id').agg(dic)\n",
    "df_temp.reset_index(level=0, inplace=True)\n",
    "df_temp.columns = new_columns\n",
    "df_temp = df_new_merchant_trans.merge(df_temp,on='card_id',how='left')\n",
    "df_train = df_train.merge(df_temp,on='card_id',how='left')\n",
    "df_test = df_test.merge(df_temp,on='card_id',how='left')\n",
    "del df_temp ;gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the following lines of code, target (as a feature) is removed from train data set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train['target']\n",
    "del df_train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following pieces of code does present the definition of a correlation matrix between variables. And all variables that present correlation over than 0.9 is removed from train and test data set. After this process the matrix is plotted one more time to verify that process work it out:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axis1) = plt.subplots(1,1,figsize=(20,15))\n",
    "# df.corr() Compute pairwise correlation of columns, excluding NA/null values.\n",
    "# sns.heatmap() Plot rectangular data as a color-encoded matrix.\n",
    "sns.heatmap(df_train.corr(),annot=True,linewidths=0.001,cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_correlated(df_in, threshold):\n",
    "   df_corr = df_in.corr(method='pearson', min_periods=1)\n",
    "\n",
    "   # np.ones() Return a new array of given shape and type, filled with ones.\n",
    "   # np.tril() Return a copy of an array with elements above the diagonal equal False.\n",
    "   # df.mask() Replace values where the condition is False.\n",
    "    \n",
    "   serie_not_correlated = ~(df_corr.mask(np.tril(np.ones(df_corr.shape, dtype=bool))).abs() > threshold).any()\n",
    "   column_corr_idx = serie_not_correlated.loc[serie_not_correlated == True].index\n",
    "   df_out = df_in[column_corr_idx]\n",
    "   return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = feature_correlated(df_train, 0.9)\n",
    "df_train_columns = [c for c in df_train.columns if c not in ['card_id','target','outliers']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axis1) = plt.subplots(1,1,figsize=(20,15))\n",
    "sns.heatmap(df_train.corr(),annot=True,linewidths=1,cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`LightGBM` is the Model selected to train and apply ML at the test data set. It is supervised learning recommended to problems that has large data sets.**\n",
    "\n",
    "**If `LightGBM` is new for you and you would like to know about it one good reference is the article [What is LightGBM](https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc) by Pushkar Mandot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "param = {'num_leaves': 31,                # defauld = 31\n",
    "         'min_data_in_leaf': 100, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,                 # default = -1, This parameter is used to handle model overfitting\n",
    "         'learning_rate': 0.01,           # The learning parameter \n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",              #  gbdt: traditional Gradient Boosting Decision Tree\n",
    "         \"feature_fraction\": 0.9,         #  LightGBM will select 90% of parameters randomly in each iteration for building trees.\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,        # 90% of data will be used for each iteration(It is used to speed up the training and avoid overfitting.)\n",
    "         \"bagging_seed\": 11,\n",
    "         \"max_cat_group\": 64\n",
    "         \"metric\": 'mse',                 # mean squared error\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 4,\n",
    "         \"random_state\": 42}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Provides train/test indices to split data in train/test sets.\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "  \n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,df_train['outliers'].values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][df_train_columns], label=target.iloc[trn_idx])#, categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][df_train_columns], label=target.iloc[val_idx])#, categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][df_train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = df_train_columns\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(df_test[df_train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "np.sqrt(mean_squared_error(oof, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
